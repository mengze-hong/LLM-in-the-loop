# Position: Embracing LLM Application with LLM-in-the-loop Machine Learning

This README serves as a guide to our reading list, highlighting key papers.

---

## Table of Contents

1. [Crowdsourcing](#crowdsourcing)
2. [LLM-in-the-Loop Keyword Paper](#llm-in-the-loop-keyword-paper)
3. [Data-Centric LLM Methods](#data-centric-llm-methods)
4. [Model-Centric Approaches](#model-centric-approaches)
5. [Task-Centric Approaches](#task-centric-approaches)


---

## Crowdsourcing
1. Spatial crowdsourcing: a survey [paper](https://link.springer.com/article/10.1007/s00778-019-00568-7)
2. ChatGPT outperforms crowd workers for text-annotation tasks [paper](https://www.pnas.org/doi/abs/10.1073/pnas.2305016120)
3. Investigating and mitigating biases in crowdsourced data [paper](https://dl.acm.org/doi/10.1145/3462204.3481729)
4. AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators [paper](https://aclanthology.org/2024.naacl-industry.15/)
5. LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages [paper](https://arxiv.org/pdf/2404.02261)
6. Large language models for mathematical reasoning: Progresses and challenges [paper](https://arxiv.org/abs/2402.00157)


---

## LLM-in-the-Loop Keyword Paper
1. Neural Topic Modeling with Large Language Models in the Loop [paper](https://arxiv.org/pdf/2411.08534)
2. LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning [paper](https://arxiv.org/pdf/2408.02999)
3. Asynchronous Large Language Model Enhanced Planner for Autonomous Driving [paper](https://arxiv.org/pdf/2406.14556)
4. Language Models in the Loop: Incorporating Prompting into Weak Supervision [paper](https://arxiv.org/pdf/2205.02318)
5. Dial-In LLM: Human-Aligned Dialogue Intent Clustering with LLM-in-the-loop [paper](https://arxiv.org/pdf/2412.09049)
6. LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis [paper](https://aclanthology.org/2023.findings-emnlp.669.pdf)
7. Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy [paper](https://arxiv.org/pdf/2404.10259)
8. LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages [paper](https://aclanthology.org/2023.findings-emnlp.669.pdf)
9. Generalized Category Discovery with Large Language Models in the Loop [paper](https://aclanthology.org/2024.findings-acl.512.pdf)
10. Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks [paper](https://arxiv.org/pdf/2406.04276)
11. Hierarchical LLMs In-the-loop Optimization for Real-time Multi-Robot Target Tracking under Unknown Hazards [paper](https://arxiv.org/pdf/2409.12274)
12. Training LLMs to Recognize Hedges in Spontaneous Narratives [paper](https://arxiv.org/pdf/2408.03319)
13. LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation [paper](https://arxiv.org/pdf/2407.12126)
14. A Rationale-centric Counterfactual Data Augmentation Method for Cross-Document Event Coreference Resolution [paper](https://arxiv.org/pdf/2404.01921)
15. Towards Single-System Illusion in Software-Defined Vehicles – Automated, AI-Powered Workflow [paper](https://arxiv.org/pdf/2403.14460)
16. Instances Need More Care: Rewriting Prompts for Instances with LLMs in the Loop Yields Better Zero-Shot Performance [paper](https://aclanthology.org/2024.findings-acl.371.pdf)

---

## Data-Centric LLM Methods 

### Data Annotation
1. Modeling and mitigating human annotation errors to design efficient stream processing systems with human-in-theloop machine learning [paper](https://arxiv.org/pdf/2007.03177)
2. Investigating and mitigating biases in crowdsourced data [paper](https://arxiv.org/pdf/2111.14322)
3. Large language models for data annotation and synthesis: A survey [paper](https://aclanthology.org/2024.emnlp-main.54.pdf)
4. Chatgpt outperforms crowd workers for text-annotation tasks [paper](https://arxiv.org/pdf/2303.15056)
5. ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification [paper](https://arxiv.org/abs/2303.03953)
6. Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zeroshot learning [paper](https://arxiv.org/pdf/2304.06588)
7. An empirical study on challenges for llm application developers [paper](https://arxiv.org/pdf/2408.05002)
8.  AnnoLLM: Making large language models to be better crowdsourced annotators [paper](https://aclanthology.org/2024.naacl-industry.15.pdf)
9.  Multi-news+: Costefficient dataset cleansing via LLM-based data annotation [paper](https://aclanthology.org/2024.emnlp-main.2.pdf)
10.  Language models in the loop: Incorporating prompting into weak supervision [paper](https://arxiv.org/pdf/2205.02318)

### Augmentation
1. Data augmentation can improve robustness [paper](https://arxiv.org/pdf/2111.05328)
2. Expanding chatbot knowledge in customer service: Context-aware similar question generation using large language models [paper](https://arxiv.org/pdf/2410.12444)
3. A new benchmark and reverse validation method for passage-level hallucination detection [paper](https://aclanthology.org/2023.findings-emnlp.256.pdf)
4. Large language model as attributed training data generator: A tale of diversity and bias [paper](https://arxiv.org/pdf/2306.15895)
5. Fusegen: Plm fusion for data-generation based zero-shot learning [paper](https://arxiv.org/pdf/2406.12527)
6. Multi-news+: Costefficient dataset cleansing via LLM-based data annotation [paper](https://aclanthology.org/2024.emnlp-main.2.pdf)
7. Fill in the gaps: Model calibration and generalization with synthetic data [paper](https://aclanthology.org/2024.emnlp-main.955.pdf)

### Feature Engineering
1. Large language models for automated data science: Introducing caafe for context-aware automated feature engineering [paper](https://arxiv.org/pdf/2305.03403)
2. Large language models for constructing and optimizing machine learning workflows: A survey [paper](https://arxiv.org/pdf/2411.10478)
3. Dynamic and adaptive feature generation with llm [paper](https://arxiv.org/pdf/2406.03505)
4. LLM-based feature generation from text for interpretable machine learning [paper](https://arxiv.org/pdf/2409.07132)
5. Informing reinforcement learning agents by grounding language to markov decision processes [paper](https://openreview.net/pdf?id=P4op21eju0)
6. Unsupervised extraction of dialogue policies from conversations [paper](https://aclanthology.org/2024.emnlp-main.1060.pdf)
7. Can chatgpt’s performance be improved on verb metaphor detection tasks? Bootstrapping and combining tacit knowledge  [paper](https://aclanthology.org/2024.acl-long.57.pdf)


---

## Model-Centric Approaches 
### Active Learning With LLM 

1. LLMaAA: Making Large Language Models as Active Annotators [paper](https://aclanthology.org/2023.findings-emnlp.872.pdf)
2. Enhancing text classification through llm-driven active learning and human
annotation [paper](https://aclanthology.org/2024.law-1.10.pdf)
3. LLMaAA: Making large language models as active annotators [paper](https://aclanthology.org/2023.findings-emnlp.872.pdf)
4. Enhancing text classification through llm-driven active learning and human
annotation [paper](https://aclanthology.org/2024.law-1.10.pdf)
5. A survey of confidence estimation and calibration in large language models [paper](https://aclanthology.org/2024.naacl-long.366.pdf)
6. Can LLMs express their uncertainty? an empirical evaluation of confidence elicitation in LLMs [paper](https://arxiv.org/pdf/2306.13063)
7.  Generalized category discovery with large language models in the loop [paper](https://aclanthology.org/2024.findings-acl.512.pdf)
8.  Dial-in llm: Human-aligned dialogue intent clustering with llm-in-the-loop [paper](https://arxiv.org/pdf/2412.09049)
9.  Neural topic modeling with large language models in the loop [paper](https://arxiv.org/pdf/2411.08534)


### Reinforcement Learning With LLM
1. Survey on large language model-enhanced reinforcement learning: Concept, taxonomy, and methods [paper](https://arxiv.org/pdf/2404.00282)
2. Aligning large language models with human preferences through representation engineering [paper](https://aclanthology.org/2024.acl-long.572.pdf)
3.  A survey on enhancing reinforcement learning in complex environments: Insights from human and llm feedback [paper](https://arxiv.org/pdf/2411.13410)
4.  Guiding pretraining in reinforcement learning with large language models [paper](https://arxiv.org/pdf/2302.06692)
5.  Reward design with language models [paper](https://arxiv.org/pdf/2303.00001)
6.  Reinforcement learning from llm feedback to counteract goal misgeneralization [paper](https://arxiv.org/pdf/2401.07181)
7.  Lagr-seq: Language-guided reinforcement learning with sample-efficient querying [paper](https://arxiv.org/pdf/2308.13542)
8.  LLM augmented hierarchical agents [paper](https://arxiv.org/pdf/2311.05596)
9.  Experience sharing and human-in-the-loop optimization for federated robot navigation recommendation [paper](https://link.springer.com/chapter/10.1007/978-3-031-51026-7_16)
10.   Federated machine learning: Concept and applications [paper](https://arxiv.org/pdf/1902.04885)


---

## Task-Centric Approaches
1. Harnessing large language models as post-hoc correctors [paper](https://aclanthology.org/2024.findings-acl.867.pdf)
2. Hyporadise: An open baseline for generative speech recognition with large language models [paper](https://arxiv.org/pdf/2309.15701)
3. Gentranslate: Large language models are generative multilingual speech and machine translators [paper](https://arxiv.org/pdf/2402.06894)
4. Large language models enable few-shot clustering [paper](https://aclanthology.org/2024.tacl-1.18.pdf)
5. Dial-in llm: Human-aligned dialogue intent clustering with llm-in-the-loop [paper](https://arxiv.org/pdf/2412.09049)
6. Enhanced short text modeling: Leveraging large language models for topic refinement [paper](https://arxiv.org/pdf/2403.17706)
7. Generating descriptive explanations of machine learning models using llm [paper](https://www.computer.org/csdl/proceedings-article/bigdata/2024/10825667/23ykhJUQhpK)
8. Improving hierarchical text clustering with llm-guided multi-view cluster representation [paper](https://aclanthology.org/2024.emnlp-industry.54.pdf)
9. Generalized category discovery with large language models in the loop [paper](https://aclanthology.org/2024.findings-acl.512.pdf)
10. Uncovering latent arguments in social media messaging by employing llms-in-the-loop strategy [paper](https://arxiv.org/pdf/2404.10259)
11. G-eval: Nlg evaluation using gpt-4 with better human alignment [paper](https://aclanthology.org/2023.emnlp-main.153.pdf)


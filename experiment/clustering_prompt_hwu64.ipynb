{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MengZe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n",
    ")\n",
    "\n",
    "def generate_cluster(selected_texts, instruction):\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": instruction},\n",
    "      {\"role\": \"user\", \"content\": f\"{list(selected_texts)}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  result = response.choices[0].message.content\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_answer(answer: str):       \n",
    "    if not answer:\n",
    "        return \"<INVALID>\"\n",
    "\n",
    "    model_pred = answer.lower()\n",
    "    preds = model_pred.split(\"<ans_start>\")\n",
    "\n",
    "    pred = preds[-1].split(\"<ans_end>\")[0].strip()\n",
    "\n",
    "    if len(pred) == 0:\n",
    "        return \"<INVALID>\"\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Siri, shuffle playlist', 'repeat song', 'Repeat the music', 'Please, put radio in shuffle.', 'repeat music', 'Please turn off shuffle setting', 'repeat this song', 'Lower battery consumption to save setting.', 'repeat jazz', 'repeat same song for 10 times', 'play only particular singer songs', 'Show current track in music player.', 'Save settings', 'shuffle music by aaron carter', 'repeat song no 10 from main list', \"Please lower the shuffle rate of hips don't lie.\", 'please go to settings of the music player and make the equalizer in the flat sound mode.', 'Please check my playlists for jazz music', \"Please program volume settings for 16 when I'm in the room at 14 for when I've gone to bed.\", 'REPLAY THE MUSICS', 'open music player settings', 'Please proceed to the next available rock song', 'Music change', 'please would you say again.', \"please could you try what you've said once more.\", 'could you say that one more time please.', 'could you tell me it once more please.', 'please say once more.', \"retry what you've just said please.\", 'could you speak one more again please.', 'i want to hear the command spoken again.', \"what's that.\", 'can you speak that one more time again.', 'will you speak it again please.', 'start over please.', 'please say one more time.', 'i would like to hear it again.', 'again please.', 'could you tell me that one more again please.', \"retry what i've said please.\", 'will you say once again please.', 'What is the best recipe for a margarita?', 'Show me pancakes PDA.', 'How to make taco?', 'recipes that can be cooked in an hour', 'How long does it take to make meatloaf?', 'what are the ingredients neccesary', 'How can I cook pasta?', 'What are the ingredients in macaroni and cheese?', 'How do I deglaze a pan?', 'how is pav bhaji cooked?', 'What is the best meatball recipe?', 'I want to know the procedure of making thanksgiving Turkey in 5 sentences.', 'PDA, what the sexiest food to cook on a date?', 'How do I make a turkey?', 'is fish and chips really British?', 'How to cook Lasagna?', 'google the steps for preparing the dish', 'Show me recipes', 'Can you prepare a cheese sandwich?', 'How do I cook a medium rare steak?', 'Could you please display the videos for cooking Italian food.', 'do you know recipe for risotto', 'Show me how to cook lasagna.', 'Look for a pizza recipe', 'Tell me how to make tacos', 'list of famous biryani recipes', 'Get recipe for making a hotdog', 'How to cook yellow rice', 'What do I need to make lamb pathia?', 'PDA, how do you zest a lime without a zester?', 'How can I debone a tilapia?', 'How do I prepare all my food for cooking?', 'How can we prepare biriyani', 'I would like the recipe for baked chicken.', 'how do you cook a good burger olly', 'whats the travel time from here to dallas by train?', 'How long does it take to get the train from Rome to Paris?', 'Next train to D.C.', 'I would like to know the train timmings to XXX [date : tomorrow].', 'How to I get to Cape Cod?', 'Hey Google, what time does the DART Orange Line leave for West Plano?', 'Tell me the train arrival time to New York', 'Give me train times from station to location', 'How far is the distance to RCCG ikoyi Lagos from here by train?', 'how much is a train ticket to chicago?', 'Hey Olly, what time does the next train depart?', 'When is the next train to Glasgow from Aberdeen?', 'Send me directions to the police department.', 'How far is it from home to Seattle?', 'get me to the nearest train station', \"PDA, What's the directions to the nearest pizza hut?\", 'when is the train arriving today?', 'How long will it take to get to Austin, TX?', 'Give me directions for the place', 'Display trains going to Antwerp after 2pm Saturday', 'would like to know the time of train X', 'what the tube like to jersey PDA?', 'go to map', 'What are the train times today?', 'Siri, how much is a train ticket', 'what are the train times from San Francisco to New York', 'fine me a train to denver', 'What time does the train run in Beaumont, Tx?', 'Take me to MC Donalds', 'running train status to..', 'Can I find the cheapest train ticket for this destination?', 'train times for tomorrow', 'Tell me my options for a train to LA next Wednesday or Thursday.', 'Are there train tickets available between Seattle and New York City', 'Please check the train schedule for Wednesday at 5pm, going to Rockville.', 'train leaving', 'Calculate the travel time if I go to orlando by train.', 'directions to mcdo?', 'How do I get home from here?', 'Olly get me a train ticket to atlanta', 'what is the status quo for traffic right now', 'What is the current traffic situation', 'can i pass the bypass road at current traffic?', 'give me the update on traffic at new york', 'How bad is traffic this morning?', 'Let me know about current traffic in Carmen Drive', 'jam', 'HOW IS TRAFFIC IN CITY', 'What is the traffic this morning?', 'PDA do you have a traffic update?', 'What is the traffic like today?', 'Can you tell me the current traffic condition of my location', 'fast road to get home', 'How long will it take me to get to the west side?', 'How is the traffic on third street?', 'what is the current traffic in washington town', 'Are there any traffic delays?', 'is it bumper to bumper', 'How is traffic from work to home.', \"How's the traffic downtown?\", 'is it possible to drive now in ohio', 'Is there traffic right now in Maiden lane?', 'What is the current traffic', 'Traffic', 'Current traffic conditions.', 'How is the traffic near me?', 'influx', 'Can you tell me about the traffic?', 'Is the road clear in Florida?', 'Accident or normal traffic', 'give me current information about traffic at central park road.', \"What's the traffic this morning?\", 'How is the traffic around city center.', 'How bad is the traffic on Sunset Boulevard?', 'Tell me the traffic condition from here to home.', 'Is the traffic smooth right now?', 'remove my morning alarm', 'Kickball is over, I do not need the alarm for kickball on Wednesday evening, any longer.', 'phones', 'pleaze remove the the alarm which i set', 'Turn off all of my alarms', 'Please cancel all alarms for tomorrow.', 'Reset the alarm.', 'pls turn off the alarm', 'snooze', 'Please remove the alarm set for Wednesday called kickball.', 'Siri, cancel yoga alarms', 'Disable the first alarm', 'personal data assistants', \"remove tomorrow's alarm\", \"Snooze all today's alarms permanently.\", 'remove wake-up calls for this week', 'Please turn off my alarm for this evening', 'can you please remove the alarm', 'Remove the alarm set for 4:00 am.', 'Set off this alarm', 'Remove Tuesday alarm of 9.00 a. m.', 'This alarm needs to be permanently silenced.', 'Remove alarm.', 'Turn off the alarm for tomorrow morning', 'reset alarm', 'remove all alarms set today', 'remove the latest alarm', 'Teach children to never answer the door when home alone.', 'I would like this alarm permanently removed', 'remove all alarms', 'Cancel the alarm that is set for tomorrow at 8 am.', 'Please remove this alarm', 'Remove my earliest alarm for tomorrow.', 'Remove alarm of 6 AM on Tuesday.', 'remove all alarms if any', 'Remove all alarm of sunday', 'please remove the alarm which i set for today morning.', 'disable the alarm which is set at 9:30pm', 'Get rid of my 8AM alarm', 'tune a radio channel for good jokes', 'Play the football game on the radio', 'play pandora', 'Go to channel 106.9', 'turn on sportsnet for hockey', 'Play the last Doctor Who radio broadcast', 'Get me some radio music from KAMP_FM', 'open fm', 'Radio', 'listen to npr radio', \"Open pandora and play top 40's hits\", 'Start radio and go to frequency on 104.8', 'play the radio station pop', 'Open Sirius app and play the classical channel', 'Please turn on one of the preprogrammed stations.', 'Showcase the radio.', 'play radio x programm 1', 'start a miley cyrus station', 'recorded program may be listened on future days', 'Play Hot 97.', 'I want to listen to the radio, turn it on for me.', 'Play the next howard stern show on the radio.', 'start drama from radio', 'Make my radio turn on', 'Open radio at [channel]', 'Open talk radio station.', 'Turn on radio now.', 'Olly, play netflix on my ps4.', 'Turn on the radio to a classical station.', 'Could you find me a jazz station?', 'Ok Google, can you start 98.7', 'Play a news radio station', 'What is the time in China ?', 'Give me the time in Phoenix, AZ', 'what is the current time in chennai', 'search for information on internet', 'whats the time in denver?', 'show time in mumbai', 'what time is it in New york', 'Get me the time in London now.', 'Please what is the current time in Paris?', 'give me the time?', 'can you tell me what time is it', 'Which day of week is the 24 th ?', 'What is the time in Geneva?', 'is it night time in Peru', 'date and time', 'Please give me the date today?', 'Time, Wellington, NZ']\n",
      "['music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'music_settings', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'general_repeat', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'cooking_recipe', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_query', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'transport_traffic', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'alarm_remove', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'play_radio', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query', 'datetime_query']\n"
     ]
    }
   ],
   "source": [
    "# Load data from banking77_sent2label.json\n",
    "with open('dataset/hwu64_sent2label.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract texts and cluster labels\n",
    "texts = list(data.keys())\n",
    "cluster_labels = list(data.values())\n",
    "\n",
    "# Print the extracted texts and cluster labels\n",
    "print(texts)\n",
    "print(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(texts)\n",
    "k = len(set(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vanilla': \"You are given a dataset of 240 sentences which you need to cluster into one of the 8 clusters. Output exactly 240 cluster labels.\\nFor each sentence, assignment it to one of the 8 cluster label and output the cluster number. Your output should ONLY contain a list of 240 integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\n  \\nExample:\\nInput Sentences: ['sentence1', 'sentence2', 'sentence3']\\nOutput Labels: [1, 0, 2]\\n\",\n",
       " 'fewshot': \"You are given a dataset of 240 sentences which you need to cluster into one of the 8 clusters. Output exactly 240 cluster labels.\\nFor each sentence, assignment it to one of the 8 cluster label and output the cluster number. Your output should ONLY contain a list of 240 integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\n  \\nExample:\\nInput Sentences: ['sentence1', 'sentence2', 'sentence3']\\nOutput Labels: [1, 0, 2]\\n \\n\\n\\n[Question] ['create a playlist of my favorite songs', 'find the nearest Thai restaurant', 'which team won the world series in 2020', 'how many calories are burnt in a 30-minute run', 'can you show me my calendar for today', 'what is the current exchange rate for usd to eur', 'write a report on the latest tech trends', 'locate a public library near me', 'turn on the AC to 70 degrees', 'what ingredients are needed for chocolate cake', 'display my latest photos', 'how to perform CPR', 'suggest a workout plan for beginners', 'play the next episode of my favorite series', 'book an appointment for a haircut']\\n[Answer] <ANS_START>[55, 72, 148, 43, 10, 136, 121, 37, 80, 43, 19, 58, 95, 76, 134]<ANS_END>\\n\\n[Question] ['change my phone wallpaper to the latest downloaded image', 'calculate the tip for a $50 meal', 'find my current GPS location', 'translate the word friendship to Spanish', 'who is the president of France', 'wake me up at 6:30 am tomorrow', 'delete all messages from my inbox', 'what time does the sun set today', 'recommend a sci-fi book', 'search for vegan recipes on the internet', 'schedule a dentist appointment for next week', 'show me directions to Central Park', 'is there a basketball game today', 'add $20 to my Starbucks card', 'when does the next train to Boston depart']\\n[Answer] <ANS_START>[21, 48, 112, 45, 132, 101, 60, 84, 91, 134, 109, 24, 105, 125, 146]<ANS_END>\\n\",\n",
       " 'cot': \"You are given a dataset of 240 sentences which you need to cluster into one of the 8 clusters. Output exactly 240 cluster labels.\\nThink step by step.\\nFor each sentence, assignment it to one of the 8 cluster label and output the cluster number. Your output should ONLY contain a list of 240 integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\n  \\nExample:\\nInput Sentences: ['sentence1', 'sentence2', 'sentence3']\\nOutput Labels: [1, 0, 2]\\n\\n\",\n",
       " 'pw_wo_reasoning': \"Expert profile: You are a data scientist with expertise in natural language processing and machine learning. You possess a deep understanding of clustering algorithms and their application to textual data. With your extensive experience, you can efficiently analyze and process datasets to uncover patterns and group sentences based on semantic similarities. You are skilled in using state-of-the-art NLP techniques and tools, such as word embeddings, vectorization, and dimensionality reduction, to convert textual data into meaningful numerical representations. Your proficiency in utilizing algorithms like k-means, hierarchical clustering, or advanced models like BERT-based clustering enables you to discern subtle differences and similarities among the sentences in the dataset. Leveraging your strong analytical and problem-solving skills, you can accurately assign each of the given 240 sentences to one of the 8 clusters, providing precise and insightful clustering labels that reflect the underlying structure of the data. Your work aids in understanding and organizing large-scale textual information efficiently.\\n\\nYou are given a dataset of 240 sentences that needs to be clustered into 8 clusters. For each sentence, assign a cluster label such that the total number of labels matches exactly 240. \\n\\nInstructions:\\n1. For each sentence, assign it to a cluster by providing a specific cluster label.\\n2. Ensure that the number of labels output is exactly the same as the number of input sentences, 240.\\n3. Format your output as a sequential list where each label corresponds to its sentence in the same order.\\n4. Verify that every sentence has a cluster label assigned without any omissions.\\n5. Double-check your final output to confirm it contains exactly 240 cluster labels.\\n  \\nExample:\\nInput Sentences: ['sentence1', 'sentence2', 'sentence3']\\nOutput Labels: [1, 0, 2]\\n\\nMake sure each output list of labels directly matches the number of sentences given.\\n\\n\\n[Question] ['create a playlist of my favorite songs', 'find the nearest Thai restaurant', 'which team won the world series in 2020', 'how many calories are burnt in a 30-minute run', 'can you show me my calendar for today', 'what is the current exchange rate for usd to eur', 'write a report on the latest tech trends', 'locate a public library near me', 'turn on the AC to 70 degrees', 'what ingredients are needed for chocolate cake', 'display my latest photos', 'how to perform CPR', 'suggest a workout plan for beginners', 'play the next episode of my favorite series', 'book an appointment for a haircut']\\n[Answer] <ANS_START>[55, 72, 148, 43, 10, 136, 121, 37, 80, 43, 19, 58, 95, 76, 134]<ANS_END>\\n\\n[Question] ['change my phone wallpaper to the latest downloaded image', 'calculate the tip for a $50 meal', 'find my current GPS location', 'translate the word friendship to Spanish', 'who is the president of France', 'wake me up at 6:30 am tomorrow', 'delete all messages from my inbox', 'what time does the sun set today', 'recommend a sci-fi book', 'search for vegan recipes on the internet', 'schedule a dentist appointment for next week', 'show me directions to Central Park', 'is there a basketball game today', 'add $20 to my Starbucks card', 'when does the next train to Boston depart']\\n[Answer] <ANS_START>[21, 48, 112, 45, 132, 101, 60, 84, 91, 134, 109, 24, 105, 125, 146]<ANS_END>\\n\\n[Question] ['order a coffee from Starbucks', 'delete my last note', 'who invented the telephone', 'paint my living room green', 'what is the square root of 144', 'find a recipe for spaghetti carbonara', 'convert 100 degrees Fahrenheit to Celsius', 'is my flight to LA on time', 'give me a summary of the book 1984', 'what are the symptoms of the flu', 'set a reminder to pick up groceries at 5 pm', 'where is the closest gas station', 'what is the speed of light', 'block spam emails in my account', 'buy tickets for the concert next Saturday']\\n[Answer] <ANS_START>[88, 144, 39, 93, 42, 24, 77, 145, 74, 112, 95, 69, 133, 60, 18]<ANS_END>\\n\\n\\nFor each sentence, assignment it to one of the 8 cluster label and output the cluster number. Your output should ONLY contain a list of 240 integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\nKeywords: Data clustering, Sentence labeling, Cluster assignment, Verification, Accuracy\\n\",\n",
       " 'pw_w_reasoning': \"Expert Profile: You are a data scientist with a strong background in machine learning, particularly in natural language processing and unsupervised learning techniques. You have expertise in text analysis and clustering algorithms, enabling you to effectively group sentences based on their semantic similarities. Your skills include applying methods such as k-means clustering, hierarchical clustering, and advanced techniques like topic modeling or sentence embeddings to create meaningful clusters. You possess a deep understanding of the nuances of language and contextual variations, ensuring that your clustering takes into account both syntactical and semantic content. By leveraging your expertise, you can output exactly 240 cluster labels, ensuring each sentence is accurately classified into one of the 8 clusters. Your analytical prowess ensures that the clustering solution is both interpretable and robust, aligning with the underlying patterns of the data.\\n\\nYou are provided with a dataset containing 240 sentences. Your task is to cluster these sentences into exactly 8 predefined clusters and return 240 cluster labels, ensuring each sentence is assigned one label corresponding to the cluster it belongs to.\\n\\n1. **Defining Predefined Clusters**: Begin by clearly defining the 8 predefined clusters based on provided guidelines or through careful inference from sentence characteristics. Avoid arbitrary cluster assignments by ensuring thorough familiarity with cluster definitions.\\n\\n2. **Consistent Output Length**: Ensure that the number of output cluster labels matches the number of input sentences. Carefully cross-check this count before finalizing your output to avoid omission errors. Emphasize the importance of maintaining a strict one-to-one correspondence between input sentences and output labels.\\n\\n3. **Clustering Approach**: Use a robust clustering method to group sentences based on semantic similarities. Consider AI models capable of semantic analysis, rule-based logic, or relevant distance metrics. Provide a succinct rationale for your chosen methodology.\\n\\n4. **Handling Ambiguous Sentences**: For sentences that do not clearly align with any cluster, assign them to the most similar predefined cluster. Clearly document your approach to ambiguous cases to avoid inconsistencies.\\n\\n5. **Error Handling**: Implement a verification step specifically designed to handle errors in output length or discrepancies in label assignments. This should include comparing the number of output labels with the number of input sentences and making necessary corrections.\\n\\n6. **Validation Process**: Employ a systematic approach to validate that each input sentence has an associated output label. Confirm that the total number of output labels precisely matches the number of input sentences.\\n\\n7. **Output Format**: Present the list of cluster labels in a sequential order matching the input sentences, ensuring clarity in the final output.\\n\\n8. **Cluster Verification**: After assignment, verify that the distribution of sentences across clusters is fair and consistent, adhering to any predefined balance criteria if applicable.\\n\\nBy adhering to these steps, ensure the accurate clustering of input sentences without omissions, preserving the integrity of the predefined clusters and the one-to-one label assignment.\\n\\n\\n[Question] ['what is the forecast for this weekend', 'can you help me learn what's trending now in fashion', 'my laptop just shut down unexpectedly; why could that be', 'how can i make the perfect cup of espresso', 'i would like to buy a pair of running shoes; which brand is the best', 'is the song playlist ready for the gym session', 'what would you recommend for a family of four visiting the zoo', 'i need a new charger; are there any durable brands', 'tell me a fun fact about space exploration', 'how do i set up a new profile on my device', 'where can i find an affordable mechanic in town', 'could you write a short paragraph on the benefits of meditation', 'i'm feeling overwhelmed; what can help with anxiety', 'should i choose wool or cotton blends for winter apparel', 'download the latest episode of my favorite podcast']\\n[Answer] To arrive at the correct clustering of sentences into predefined clusters, follow these detailed steps:\\n\\n1. **Understand the Input**: We have a list of sentences [Question] requiring categorization into 8 predefined clusters. The total number of sentences is 240.\\n\\n2. **Define Predefined Clusters**: Initially, clusters were implicitly defined through prior familiarization or characteristics observed in example datasets. Here, assume clusters correspond to distinct topics or categories relevant to the sentences, such as “Weather Forecast”, “Fashion Trends”, “Technical Support”, “Food/Beverage”, “Shopping Recommendations”, “Music”, “Family Activities”, “Electronics”, “Space/Facts”, “Device Setup”, “Service Providers”, “Personal Development”, “Mental Health”, “Clothing Choices”, and “Entertainment/Media”.\\n\\n3. **Sentence Analysis and Clustering Approach**:\\n   - For semantic similarities: Employ a natural language processing model like BERT to encapture the context and meaning of each sentence.\\n   - Using embeddings from such models, calculate distances between sentence vectors to understand topic similarities.\\n   - Label sentences by similarity to these predefined cluster vectors through a method like k-means clustering, or with heuristic rules derived from the clarity of domain knowledge.\\n\\n4. **Assigning Clusters**:\\n   - Analyze each sentence, determining its semantic content and aligning it with the closest predefined cluster.\\n   - For example, the sentence 'what is the forecast for this weekend' would align with a cluster about weather.\\n   - Sentences about technical support (like 'my laptop just shut down unexpectedly; why could that be') would align with a different cluster relevant to technology.\\n\\n5. **Handling Ambiguous Sentences**:\\n   - For any ambiguous sentences, apply a nearest-neighbor approach or assign them based on secondary keywords indicating a cluster and document the rationale.\\n\\n6. **Verify Sentence-Cluster Consistency**:\\n   - Ensure each of the 240 sentences has an associated cluster label by analyzing the output count.\\n   - Confirm with manual verification that ambiguous sentences are reasonably assigned to the closest clusters based on topic or intent.\\n\\n7. **Output Maintenance**:\\n   - Once assigned, list down cluster labels for output in order, addressing each sentence’s position in the input list to ensure readability and clarity in presentation.\\n  \\n8. **Verify Clustering**:\\n   - Conduct a post-assignment review to verify that the distribution across clusters is balanced or proportional to input uncertainties.\\n   - Double-check that no sentences are left unassigned or grouped incorrectly due to oversight.\\n\\n9. **Output the Cluster Labels**: Following these steps, produce the output label for each input sentence, as depicted in the example answers: [9, 45, 123, 145, 57, 89, 68, 106, 33, 77, 54, 131, 87, 53, 142], ensuring each number corresponds to a functioning and meaning-based cluster assignment of sentences.\\n\\nThrough this detailed reasoning chain, the final list of cluster labels should accurately reflect the grouping of input sentences into the 8 distinct clusters, staying faithful to initial guidelines and submitted in a consistent, orderly format. <ANS_START>[9, 45, 123, 145, 57, 89, 68, 106, 33, 77, 54, 131, 87, 53, 142]<ANS_END>\\n\\n[Question] ['explain how machine learning can improve healthcare', 'can you find the nearest vegan restaurant that delivers', 'after the meeting, remind me to check my emails', 'what is the process for resetting a forgotten password', 'are there any romantic comedies released this year', 'is it more efficient to batch process tasks in the morning', 'are there any updates on the local sports team', 'how do you handle stress at work effectively', 'identify the main themes in the novel 1984', 'suggest a movie that has a similar vibe to inception', 'what's the usual turnaround time for car repairs', 'could you record the meeting notes and send them to everyone', 'what is the role of antioxidants in skincare', 'i need to calculate how much paint i need for my bedroom']\\n[Answer] To accurately cluster the given sentences into predefined clusters, we need to follow a structured process, adhering to the outlined task description and instructions. Below is the step-by-step reasoning chain that guides us through this task:\\n\\n1. **Understanding Predefined Clusters**:\\n   - Begin by categorizing sentences into distinct themes or topics, which represent the predefined clusters. These could be topics like healthcare, dining, task management, technology, entertainment, sports, work-life balance, literature, cinematic experiences, automotive, professional reminders, skincare, and home improvement calculations.\\n\\n2. **Sentence Analysis**:\\n   - Carefully read each sentence to understand its main theme or topic. This involves semantic analysis which might involve using natural language processing (NLP) techniques to capture the underlying themes and topics.\\n\\n3. **Cluster Assignments**:\\n   - Assign each sentence to the most relevant cluster based on the detected theme. This would require aligning the sentence context to one of the predefined clusters and being consistent with interpretations across all sentences.\\n\\n4. **Handling Ambiguities**:\\n   - If a sentence seems ambiguous or potentially fits multiple clusters, use contextual cues within the sentence to determine the strongest association. When necessary, leverage external domain knowledge to make a more informed decision.\\n\\n5. **Verification of Output Consistency**:\\n   - Ensure that the number of labels outputs equals the number of input sentences, i.e., each sentence must be assigned to precisely one cluster without any omissions or duplications.\\n\\n6. **Output Formatting**:\\n   - Present cluster labels in a one-to-one correspondence with the input sentences, maintaining the same sequential order as the input list.\\n\\n7. **Rationale for Methodology**:\\n   - Document the chosen clustering methodology, which might involve using AI models for semantic processing, manual rule-based sorting, or distance metrics in a vector space, explaining why this method is robust and suitable for the task.\\n\\n8. **Validation and Error Handling**:\\n   - Conduct a final verification check to ensure the correct number of labels and fair distribution among clusters, making adjustments as needed to comply with any guidelines on balancing and integrity.\\n\\nUsing this reasoning chain ensures that each sentence is thoroughly analyzed, correctly clustered, and output in a coherent manner. The labels themselves are representative of the logical sequence in which each sentence aligns with the inferred or defined cluster criteria, ensuring accurate and meaningful clustering outcomes. <ANS_START>[113, 75, 152, 44, 39, 122, 137, 15, 91, 29, 48, 97, 66, 138]<ANS_END>\\n\\n[Question] ['brainstorm creative ways to recycle plastic', 'how do i cook a steak to medium rare', 'what are the ethical implications of artificial intelligence', 'how can i troubleshoot the wifi connectivity issues', 'i'd like to explore different genres of music', 'are there any historical documentaries worth watching', 'guide me through setting up a business account', 'help me compile a list of recipes for a vegan diet', 'could you play a soothing playlist for relaxation', 'what strategies increase productivity while working from home', 'why doesn't my device recognize my fingerprint', 'what are the top three tourist attractions in paris', 'explain the significance of the renaissance period', 'how can i locate my misplaced phone']\\n[Answer] To effectively solve the problem of clustering the given sentences into the predefined clusters, we need to follow a systematic approach. Here's a comprehensive reasoning chain detailing the necessary steps:\\n\\n1. **Understand the Clustering Objective**: We're tasked with clustering sentences into predefined categories. For the example given, cluster IDs such as 24, 59, 110, etc., represent these predefined categories.\\n\\n2. **Preprocess the Sentences**: Begin by analyzing each sentence to discern its key themes or subject matter. Recognize specific keywords or phrases within each sentence that indicate the topic. For instance, words like 'recycle,' 'plastic,' and 'creative' in 'brainstorm creative ways to recycle plastic' signal a focus on environmental concerns or innovation.\\n\\n3. **Identify Predefined Clusters**: Determine the shared characteristics or themes that define each cluster:\\n   - Cluster 24 might relate to environmental issues or creativity.\\n   - Cluster 59 could be linked to culinary techniques or food preparation.\\n   - Cluster 110 might focus on technological ethics or consequences.\\n   - Continue this process for each cluster, understanding their distinguishing characteristics.\\n\\n4. **Sentence Analysis and Matching**: For each sentence, perform semantic analysis using AI models or heuristic rules to match the sentence with the most fitting cluster:\\n   - 'brainstorm creative ways to recycle plastic' aligns with environmental creativity (potentially cluster 24).\\n   - 'how do i cook a steak to medium rare' relates to cooking methods (potentially cluster 59).\\n   - Ensure each sentence is assessed on similarity based on content themes.\\n\\n5. **Handle Ambiguities**: If a sentence like 'how can i locate my misplaced phone' does not clearly match an obvious cluster, evaluate its closest semantic match and assign it accordingly. Here, it might relate to personal technology and get assigned to a relevant cluster such as 66 (representing practical technology usage).\\n\\n6. **Cross-Verification**:\\n   - Verify that each assigned label corresponds to one input sentence without omissions.\\n   - Ensure the total number of cluster labels matches the number of input sentences (14 in this context).\\n\\n7. **Output Validation**: \\n   - Review the entire set of cluster assignments for logical consistency.\\n   - Check balance, ensuring no predominant leaning unless explicitly required by the task briefing.\\n\\n8. **Produce Sequential Output**: Arrange the finalized cluster labels in the exact sequence the sentences were provided to maintain the one-to-one mapping from sentence to cluster label.\\n\\nBy executing these steps, we achieve a robust and coherent clustering of sentences into predefined labels, confirming the correct association between sentences and assigned clusters: [24, 59, 110, 102, 78, 114, 91, 123, 86, 20, 43, 82, 126, 66]. <ANS_START>[24, 59, 110, 102, 78, 114, 91, 123, 86, 20, 43, 82, 126, 66]<ANS_END>\\n\\n\\nFor each sentence, assignment it to one of the 8 cluster label and output the cluster number. Your output should ONLY contain a list of 240 integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\nKeywords: semantic analysis, clustering method, predefined clusters, error handling, label consistency\\n\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load prompt\n",
    "with open('prompt_template.json', 'r', encoding=\"utf-8\") as file:\n",
    "    prompt_template = json.load(file)\n",
    "\n",
    "for prompt in prompt_template.keys():\n",
    "    prompt_template[prompt] = prompt_template[prompt].replace(\"{n}\", str(n)).replace(\"{k}\", str(k))\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompt_template.keys():\n",
    "    results = []\n",
    "    instruction = prompt_template[prompt]\n",
    "    print(f\"#### Running with prompt - {prompt}\\n\")\n",
    "    with open(f'clustering_result/hwu64_prompt/prompting_results_{prompt}_hwu64.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in tqdm(range(0, 50)):\n",
    "            try:\n",
    "                result = generate_cluster(texts, instruction)\n",
    "            except Exception as e:\n",
    "                print(f\"GPT Error: {e}\")\n",
    "                break\n",
    "            try:\n",
    "                processed_result = extract_final_answer(result)         # Extract the final answer from the result\n",
    "            except:\n",
    "                print(\"INVALID OUTPUT\")\n",
    "                print(result)\n",
    "                break\n",
    "            label_count = len(processed_result[1:-1].split(\", \"))         # Count the number of labels in the processed result\n",
    "            writer.writerow([i, label_count, processed_result])\n",
    "            results.append({'Iteration': i, 'Label Count': label_count, 'Processed Result': processed_result})\n",
    "            \n",
    "    # Convert the results to a DataFrame\n",
    "    # df_results = pd.DataFrame(results)\n",
    "    # df_label_counts = pd.read_csv('prompting_label_counts_hwu64.csv')\n",
    "    # df_label_counts[f\"{prompt}\"] = df_results[\"Label Count\"]\n",
    "\n",
    "    # df_label_counts.to_csv('prompting_label_counts_hwu64.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\1686031612.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\1686031612.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\1686031612.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\1686031612.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\1686031612.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n"
     ]
    }
   ],
   "source": [
    "hwu64_count = pd.read_csv(\"clustering_result/count_statistics/prompting_label_counts_hwu64.csv\")\n",
    "\n",
    "for prompt in prompt_template.keys():\n",
    "    df = pd.read_csv(f'clustering_result/hwu64_prompt/prompting_results_{prompt}_hwu64.csv')\n",
    "    df.columns = ['Index', 'Label Count', 'Cluster Assignment']\n",
    "    for i, row in df.iterrows():\n",
    "        df.at[i, 'Index'] = int(i)+1\n",
    "        cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
    "        df.at[i, 'Label Count'] = int(len(cluster))\n",
    "    df['Label Count'] = df['Label Count'].astype(int)\n",
    "    df.to_csv(f'clustering_result/hwu64_prompt/prompting_results_{prompt}_hwu64.csv', index=None)\n",
    "    hwu64_count[f\"{prompt}\"] = df['Label Count']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>less than</th>\n",
       "      <th>equal to</th>\n",
       "      <th>greater than</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pw_wo_reasoning</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pw_w_reasoning</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 less than  equal to  greater than\n",
       "vanilla                 12         1            37\n",
       "cot                      7         0            43\n",
       "fewshot                 19         2            29\n",
       "pw_wo_reasoning          0         1            49\n",
       "pw_w_reasoning           6         0            44"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 240\n",
    "\n",
    "counts = {}\n",
    "\n",
    "for col in hwu64_count.columns:\n",
    "    counts[col] = {\n",
    "        'less than': (hwu64_count[col] < threshold).sum(),\n",
    "        'equal to': (hwu64_count[col] == threshold).sum(),\n",
    "        'greater than': (hwu64_count[col] > threshold).sum()\n",
    "    }\n",
    "\n",
    "counts_df = pd.DataFrame(counts).T\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla: 20\n",
      "fewshot: 16\n",
      "cot: 12\n",
      "pw_wo_reasoning: 17\n",
      "pw_w_reasoning: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\2711038660.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\2711038660.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\2711038660.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\2711038660.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\2711038660.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompt_template.keys():\n",
    "    df = pd.read_csv(f'clustering_result/hwu64_prompt/prompting_results_{prompt}_hwu64.csv')\n",
    "    df.columns = ['Index', 'Label Count', 'Cluster Assignment']\n",
    "    counter = 0\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            cluster = [x.strip() for x in row[2][1:-1].split(\",\")]\n",
    "            labels = list(map(int, cluster))\n",
    "        except:\n",
    "            print(i)\n",
    "        if len(set(labels)) < 8:\n",
    "            counter += 1\n",
    "    print(f\"{prompt}: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla: 0.7893023483840297\n",
      "fewshot: 0.7939332460566361\n",
      "fewshot: 0.7686341924216898\n",
      "pw_wo_reasoning: 0.8233843028539108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\987409121.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels = list(map(int, row[2][1:-1].split(\", \")))\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\987409121.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels = list(map(int, row[2][1:-1].split(\", \")))\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\987409121.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels = list(map(int, row[2][1:-1].split(\", \")))\n",
      "C:\\Users\\MengZe\\AppData\\Local\\Temp\\ipykernel_13808\\987409121.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  labels = list(map(int, row[2][1:-1].split(\", \")))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "for prompt in prompt_template.keys():\n",
    "    df = pd.read_csv(f'clustering_result/hwu64_prompt/prompting_results_{prompt}_hwu64.csv')\n",
    "    df.columns = ['Index', 'Label Count', 'Cluster Assignment']\n",
    "    for i, row in df.iterrows():\n",
    "        if row[\"Label Count\"] == n:\n",
    "            labels = list(map(int, row[2][1:-1].split(\", \")))\n",
    "            nmi = normalized_mutual_info_score(labels, cluster_labels)\n",
    "            print(f\"{prompt}: {nmi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

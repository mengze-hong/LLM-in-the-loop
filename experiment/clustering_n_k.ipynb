{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n",
    ")\n",
    "\n",
    "def generate_cluster(selected_texts, expert_profile, best_prompt):\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": expert_profile + \"\\n\" + best_prompt + \"\\n\"},\n",
    "      {\"role\": \"user\", \"content\": f\"{list(selected_texts)}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  result = response.choices[0].message.content\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_answer(answer: str):       \n",
    "    if not answer:\n",
    "        return \"<INVALID>\"\n",
    "\n",
    "    model_pred = answer.lower()\n",
    "    preds = model_pred.split(\"<ans_start>\")\n",
    "\n",
    "    pred = preds[-1].split(\"<ans_end>\")[0].strip()\n",
    "\n",
    "    if len(pred) == 0:\n",
    "        return \"<INVALID>\"\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"clinc_oos\", \"small\")\n",
    "\n",
    "test_split = dataset[\"test\"]\n",
    "texts = test_split[\"text\"]\n",
    "intents = test_split[\"intent\"]\n",
    "\n",
    "# Filter out intent 42\n",
    "filtered_pairs = [(t, i) for (t, i) in zip(texts, intents) if i != 42]\n",
    "filtered_texts, filtered_intents = zip(*filtered_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = [(text, intent) for text, intent in filtered_pairs if 0 <= intent <= 3]\n",
    "selected_texts, selected_intents = zip(*selected_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5220"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((\" \").join(list(selected_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4338"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expert_profile + best_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt_wizard_180_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Initialize an empty list to store the results\n",
    "for k in tqdm([2,4,6,8,10,12,14,16,18,20]):\n",
    "    results = []\n",
    "    selected_pairs = [(text, intent) for text, intent in filtered_pairs if 0 <= intent <= k-1]\n",
    "    selected_texts, selected_intents = zip(*selected_pairs)\n",
    "\n",
    "    n = len(selected_texts)\n",
    "    k = len(set(selected_intents))\n",
    "    \n",
    "    print(f\"running prompt_wizard_{n}_{k}.csv\")\n",
    "\n",
    "    expert_profile = \"Expert profile: You are a data scientist with expertise in natural language processing and machine learning. You possess a deep understanding of clustering algorithms and their application to textual data. With your extensive experience, you can efficiently analyze and process datasets to uncover patterns and group sentences based on semantic similarities. You are skilled in using state-of-the-art NLP techniques and tools, such as word embeddings, vectorization, and dimensionality reduction, to convert textual data into meaningful numerical representations. Your proficiency in utilizing algorithms like k-means, hierarchical clustering, or advanced models like BERT-based clustering enables you to discern subtle differences and similarities among the sentences in the dataset. Leveraging your strong analytical and problem-solving skills, you can accurately assign each of the given {n} sentences to one of the {k} clusters, providing precise and insightful clustering labels that reflect the underlying structure of the data. Your work aids in understanding and organizing large-scale textual information efficiently.\"\n",
    "    best_prompt = f\"\\nYou are given a dataset of {n} sentences that needs to be clustered into {k} clusters. For each sentence, assign a cluster label such that the total number of labels matches exactly {n}. \\n\\nInstructions:\\n1. For each sentence, assign it to a cluster by providing a specific cluster label.\\n2. Ensure that the number of labels output is exactly the same as the number of input sentences, {n}.\\n3. Format your output as a sequential list where each label corresponds to its sentence in the same order.\\n4. Verify that every sentence has a cluster label assigned without any omissions.\\n5. Double-check your final output to confirm it contains exactly {n} cluster labels.\\n  \\nExample:\\nInput Sentences: [\\'sentence1\\', \\'sentence2\\', \\'sentence3\\']\\nOutput Labels: [1, 0, 2]\\n  \\nMake sure each output list of labels directly matches the number of sentences given.\\n\\n\\n[Question] [\\'create a playlist of my favorite songs\\', \\'find the nearest Thai restaurant\\', \\'which team won the world series in 2020\\', \\'how many calories are burnt in a 30-minute run\\', \\'can you show me my calendar for today\\', \\'what is the current exchange rate for usd to eur\\', \\'write a report on the latest tech trends\\', \\'locate a public library near me\\', \\'turn on the AC to 70 degrees\\', \\'what ingredients are needed for chocolate cake\\', \\'display my latest photos\\', \\'how to perform CPR\\', \\'suggest a workout plan for beginners\\', \\'play the next episode of my favorite series\\', \\'book an appointment for a haircut\\']\\n[Answer] <ANS_START>[55, 72, 148, 43, 10, 136, 121, 37, 80, 43, 19, 58, 95, 76, 134]<ANS_END>\\n\\n[Question] [\\'change my phone wallpaper to the latest downloaded image\\', \\'calculate the tip for a $50 meal\\', \\'find my current GPS location\\', \\'translate the word friendship to Spanish\\', \\'who is the president of France\\', \\'wake me up at 6:30 am tomorrow\\', \\'delete all messages from my inbox\\', \\'what time does the sun set today\\', \\'recommend a sci-fi book\\', \\'search for vegan recipes on the internet\\', \\'schedule a dentist appointment for next week\\', \\'show me directions to Central Park\\', \\'is there a basketball game today\\', \\'add $20 to my Starbucks card\\', \\'when does the next train to Boston depart\\']\\n[Answer] <ANS_START>[21, 48, 112, 45, 132, 101, 60, 84, 91, 134, 109, 24, 105, 125, 146]<ANS_END>\\n\\n[Question] [\\'order a coffee from Starbucks\\', \\'delete my last note\\', \\'who invented the telephone\\', \\'paint my living room green\\', \\'what is the square root of 144\\', \\'find a recipe for spaghetti carbonara\\', \\'convert 100 degrees Fahrenheit to Celsius\\', \\'is my flight to LA on time\\', \\'give me a summary of the book 1984\\', \\'what are the symptoms of the flu\\', \\'set a reminder to pick up groceries at 5 pm\\', \\'where is the closest gas station\\', \\'what is the speed of light\\', \\'block spam emails in my account\\', \\'buy tickets for the concert next Saturday\\']\\n[Answer] <ANS_START>[88, 144, 39, 93, 42, 24, 77, 145, 74, 112, 95, 69, 133, 60, 18]<ANS_END>\\n\\n\\nFor each sentence, assignment it to one of the {k} cluster label and output the cluster number. Your output should ONLY contain a list of {n} integers in the format <ANS_START>[cluster asignments]<ANS_END>. Do not include any other texts.\\nKeywords: Data clustering, Sentence labeling, Cluster assignment, Verification, Accuracy\"\n",
    "\n",
    "    # Save the processed result and the count in a CSV file\n",
    "    with open(f'prompt_wizard_{n}_{k}.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # writer.writerow(['Iteration', 'Label Count', 'Processed Result'])\n",
    "        for i in tqdm(range(0, 50)):\n",
    "            try:\n",
    "                result = generate_cluster(selected_texts, expert_profile, best_prompt)\n",
    "                # print(result)\n",
    "            except:\n",
    "                print(\"GPT Error\")\n",
    "                continue\n",
    "            try:\n",
    "                processed_result = extract_final_answer(result)         # Extract the final answer from the result\n",
    "            except:\n",
    "                print(\"INVALID OUTPUT\")\n",
    "                print(result)\n",
    "                break\n",
    "            label_count = len(processed_result[1:-1].split(\", \"))         # Count the number of labels in the processed result\n",
    "            writer.writerow([i, label_count, processed_result])\n",
    "            results.append({'Iteration': i, 'Label Count': label_count, 'Processed Result': processed_result})\n",
    "            \n",
    "    # Convert the results to a DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(f\"clustering_result/n_k/prompt_wizard_{n}_{k}_add.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60_2\n",
      "90_3\n",
      "120_4\n",
      "150_5\n",
      "240_8\n",
      "300_10\n",
      "600_20\n",
      "180_6\n",
      "450_15\n",
      "360_12\n",
      "420_14\n",
      "480_16\n"
     ]
    }
   ],
   "source": [
    "# Convert the results to a DataFrame\n",
    "df_label_counts = pd.read_csv('clustering_tasks_label_counts.csv')\n",
    "\n",
    "for col in df_label_counts.columns:\n",
    "    print(col)\n",
    "    df_results = pd.read_csv(f\"clustering_result/n_k/prompt_wizard_{col}.csv\", header=None)\n",
    "    df_results.columns = ['Iteration', 'Label Count', 'Processed Result']\n",
    "\n",
    "    df_label_counts[f\"{col}\"] = df_results[\"Label Count\"]\n",
    "\n",
    "    df_label_counts.to_csv('clustering_tasks_label_counts.csv', index=False)\n",
    "    \n",
    "df_label_counts = df_label_counts.reindex(sorted(df_label_counts.columns), axis=1)\n",
    "df_label_counts.to_csv('clustering_tasks_label_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(df, points=False):\n",
    "    # Set the aesthetic style of the plots\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    # Define the columns to plot\n",
    "    columns = df.columns\n",
    "\n",
    "    # Define a color palette suitable for nature publications\n",
    "    palette = sns.color_palette(\"pastel\", len(columns))  # Use a colorblind-friendly palette\n",
    "\n",
    "    # Melt the DataFrame to long format for seaborn\n",
    "    melted_df = df[columns].melt(var_name='Label', value_name='Count')\n",
    "\n",
    "    # Create a single violin plot for all columns\n",
    "    plt.figure(figsize=(8, 5))  # Make the figure less wide and more compact\n",
    "    sns.violinplot(x='Label', y='Count', data=melted_df, scale='area', palette=palette, inner=\"quartile\", linewidth=1.2)\n",
    "\n",
    "    # Set title and labels with enhanced font size\n",
    "    # plt.title('Violin Plot of Label Counts', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Configuration', fontsize=14)\n",
    "    plt.ylabel('Number of Labels', fontsize=14)\n",
    "\n",
    "    # Customize the tick parameters\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    if points:\n",
    "        # Draw dots to indicate specific label values\n",
    "        for index, value in enumerate([col.split('_')[0] for col in df.columns]):\n",
    "            plt.plot(index, int(value), 'ro', markersize=8)  # Plot a red dot at the specified y-value\n",
    "            # plt.text(index, value + 5, f'{value}', color='red', fontsize=10, ha='center', va='bottom')  # Adjust annotation position\n",
    "\n",
    "    # Adjust the layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "df = pd.read_csv('clustering_tasks_label_counts.csv')\n",
    "\n",
    "df = df.drop(columns=[\"60_2\", \"90_3\", \"150_5\", \"450_15\"])\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "plot_violin(df, points=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
